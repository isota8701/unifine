{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366f21a2-37d6-49d0-a78b-79eb8021d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd89d298-a7eb-4394-9a4d-77cbb0c96d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import cfg, cfg_from_file\n",
    "import os\n",
    "from data import MaterialLoader, EvalLoader\n",
    "from pretrain import preTrainer\n",
    "from evaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69007516-6e8c-4748-8181-4b0019657afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DEVICE = 'cuda:2'\n",
    "cfg.FROM_PATH = True\n",
    "cfg.CUT_DATA = False\n",
    "cfg.DATASET_NAME = \"mp_3d_2020_maxA20_N48840_CUT_3600\"\n",
    "cfg.TRAIN.max_epoch = 50\n",
    "cfg.TRAIN.snapshot_interval = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c0320c-9d2b-4fc6-8ae7-34de463acc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Test condition\n",
    "\n",
    "Formula CGConv\n",
    "reparametrize at input stage\n",
    "sg_nce_loss+=\n",
    "lr 0.001\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6578493-d70c-4add-b9e4-66ce7a102be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset\n",
      "Loading from path, dataset name : mp_3d_2020_maxA20_N48840_CUT_3600\n",
      "NUM TRAIN:3240, NUM VALID:180, NUM_TEST:180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 299/300 [01:14<00:00,  4.03it/s]\n",
      "100%|█████████▉| 299/300 [01:14<00:00,  4.00it/s]\n",
      "100%|█████████▉| 299/300 [01:16<00:00,  3.91it/s]\n",
      "100%|█████████▉| 299/300 [01:16<00:00,  3.90it/s]\n",
      "100%|█████████▉| 299/300 [01:17<00:00,  3.84it/s]\n",
      "100%|█████████▉| 299/300 [01:17<00:00,  3.83it/s]\n",
      "100%|█████████▉| 299/300 [01:18<00:00,  3.81it/s]\n",
      "100%|█████████▉| 299/300 [01:18<00:00,  3.80it/s]\n",
      "100%|█████████▉| 299/300 [01:20<00:00,  3.69it/s]\n",
      "100%|█████████▉| 299/300 [01:21<00:00,  3.66it/s]\n",
      "100%|█████████▉| 299/300 [01:20<00:00,  3.71it/s]\n",
      "100%|█████████▉| 299/300 [01:23<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph building issue, 0 discarded from train data\n",
      "## Start pre-training\n",
      "Epoch 5/50  Train loss :12.6167  Valid loss:12.4460  Interval time elapsed: 0.0267\n",
      "Train loss details\n",
      "atom feat recon loss:0.28  adj recon loss:1.07  space group loss:4.58  space group contrastive loss:3.16  2d 3d contrastive loss:  2.60  input kld loss:  29.05 source target embedding diff loss :0.64\n",
      "Epoch 10/50  Train loss :11.3333  Valid loss:11.4541  Interval time elapsed: 0.0535\n",
      "Train loss details\n",
      "atom feat recon loss:0.25  adj recon loss:0.97  space group loss:4.12  space group contrastive loss:2.76  2d 3d contrastive loss:  2.36  input kld loss:  26.89 source target embedding diff loss :0.61\n",
      "Epoch 15/50  Train loss :10.6273  Valid loss:11.1819  Interval time elapsed: 0.0802\n",
      "Train loss details\n",
      "atom feat recon loss:0.23  adj recon loss:0.86  space group loss:3.90  space group contrastive loss:2.67  2d 3d contrastive loss:  2.10  input kld loss:  27.63 source target embedding diff loss :0.60\n",
      "Epoch 20/50  Train loss :9.9562  Valid loss:10.6874  Interval time elapsed: 0.1069\n",
      "Train loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.77  space group loss:3.75  space group contrastive loss:2.44  2d 3d contrastive loss:  1.92  input kld loss:  27.74 source target embedding diff loss :0.59\n",
      "Epoch 25/50  Train loss :9.3659  Valid loss:10.6956  Interval time elapsed: 0.1337\n",
      "Train loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.77  space group loss:3.63  space group contrastive loss:2.04  2d 3d contrastive loss:  1.84  input kld loss:  28.58 source target embedding diff loss :0.58\n",
      "Epoch 30/50  Train loss :8.6106  Valid loss:10.5993  Interval time elapsed: 0.1604\n",
      "Train loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.76  space group loss:3.51  space group contrastive loss:1.42  2d 3d contrastive loss:  1.84  input kld loss:  28.35 source target embedding diff loss :0.58\n",
      "Epoch 35/50  Train loss :7.7961  Valid loss:10.7902  Interval time elapsed: 0.1873\n",
      "Train loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.72  space group loss:3.43  space group contrastive loss:0.81  2d 3d contrastive loss:  1.75  input kld loss:  28.40 source target embedding diff loss :0.58\n",
      "Epoch 40/50  Train loss :7.3520  Valid loss:10.5890  Interval time elapsed: 0.2139\n",
      "Train loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.68  space group loss:3.39  space group contrastive loss:0.53  2d 3d contrastive loss:  1.68  input kld loss:  28.49 source target embedding diff loss :0.58\n",
      "Epoch 45/50  Train loss :7.1891  Valid loss:10.3759  Interval time elapsed: 0.2404\n",
      "Train loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.67  space group loss:3.38  space group contrastive loss:0.42  2d 3d contrastive loss:  1.65  input kld loss:  28.50 source target embedding diff loss :0.58\n",
      "Epoch 50/50  Train loss :7.1490  Valid loss:10.3660  Interval time elapsed: 0.2989\n",
      "Train loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.66  space group loss:3.38  space group contrastive loss:0.40  2d 3d contrastive loss:  1.63  input kld loss:  28.43 source target embedding diff loss :0.58\n",
      "Training done\n",
      "Best epoch :42  Best Valid loss: 10.3162\n",
      "Test Loss: 10.7192\n",
      "Test loss details\n",
      "atom feat recon loss:0.22  adj recon loss:0.84  space group loss:3.59  space group contrastive loss:3.73  2d 3d contrastive loss:  1.49  input kld loss:  28.69 source target embedding diff loss :0.57\n",
      "Total time elapsed: 0.2989\n"
     ]
    }
   ],
   "source": [
    "train_loader , valid_loader, test_loader = MaterialLoader()\n",
    "ptrainer = preTrainer(train_loader, valid_loader, test_loader)\n",
    "ptrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1584c6ff-6f75-4d7d-bfce-372b5733071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6833, -0.8699,  0.6895],\n",
       "        [-0.6833, -0.8699,  0.6895]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "oo = torch.ones(2,5)\n",
    "lin = nn.Linear(5,3)\n",
    "lin(oo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c828d50-110e-42f8-a430-ab20a30cd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = torch.randn(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "342d1078-9332-473a-9648-ef7578a0f8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef3c0a2e-3e5a-4589-bf58-804e15174674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6427,  0.6639, -0.5135],\n",
       "        [-0.2638,  1.1413,  0.3218],\n",
       "        [-0.5501,  0.2651,  0.1670],\n",
       "        [ 0.4163, -2.3609, -0.9746],\n",
       "        [ 2.2786,  0.2211, -1.0350]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7cfaeab-f7c3-4581-aa49-c3b37fd4d995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5237, -0.0694, -2.0344],\n",
       "        [ 2.5237, -0.0694, -2.0344]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oo@bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8513e871-4d4d-4e04-aefc-ec381b44ce33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5237, -0.0694, -2.0344])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc784f29-cbe8-4bb9-b154-5ac89fc4cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.ones(10,2,5)\n",
    "www = torch.randn(10, 5,2)\n",
    "out = torch.matmul(inp, www)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38f45465-6fd7-4afe-9dc7-f2c7da03da2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.mean(dim = 1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e63ebc6-57ae-4507-ba7a-8cf21dfaa0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9176,  0.8993],\n",
       "         [ 0.9176,  0.8993]],\n",
       "\n",
       "        [[-1.5300, -0.9391],\n",
       "         [-1.5300, -0.9391]],\n",
       "\n",
       "        [[ 7.6285,  0.7230],\n",
       "         [ 7.6285,  0.7230]],\n",
       "\n",
       "        [[ 1.3110,  2.5624],\n",
       "         [ 1.3110,  2.5624]],\n",
       "\n",
       "        [[ 0.5787,  1.2655],\n",
       "         [ 0.5787,  1.2655]],\n",
       "\n",
       "        [[ 3.0386,  2.8315],\n",
       "         [ 3.0386,  2.8315]],\n",
       "\n",
       "        [[-0.7460,  1.3690],\n",
       "         [-0.7460,  1.3690]],\n",
       "\n",
       "        [[ 0.1284, -0.5964],\n",
       "         [ 0.1284, -0.5964]],\n",
       "\n",
       "        [[ 2.9800, -3.0482],\n",
       "         [ 2.9800, -3.0482]],\n",
       "\n",
       "        [[ 3.8682,  1.2729],\n",
       "         [ 3.8682,  1.2729]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7daaadbc-9b08-49a3-87b3-4c853e8f2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "inx = out.mean(dim=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e72780eb-0c9b-4880-8e45-014d47b0e062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2aa2bec6-27f9-4746-a848-6ad5e2a18546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_out = nn.Linear(10,1)\n",
    "lin_out(inx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ccf069f3-b420-4095-8054-d03d14a37da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9537],\n",
       "        [0.1196]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_out(inx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32db03c1-0771-4868-8a99-580b56ed8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e81536be-b9a5-47c8-a886-13d1f26737c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8175, 0.6340])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1a8a724c-66dd-4be3-8fa0-ad0c5b3c33cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(y=[256, 1], y_batch=[256], y_ptr=[257], node_features_s=[1127, 92], atom_types_s=[1127], edge_index_s=[2, 6521], atom_weights_s=[6521, 1], batch=[1127], ptr=[257])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa9ee1a-6a06-4ddf-93d0-d9b5afd71bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006ad28-3873-4006-bb55-fccc21d4c2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc5d44-5445-4136-b40a-de6ca55f53e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bbffa-930a-4cdb-8d39-7fe0e8c96deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0f9fc-696c-4d6b-a41f-9c31d01da1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ad2a6-272a-43ae-b44c-dfca1a9a61cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9925a18-f91a-4d9e-8207-998c29f45d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.EVAL.dataset = \"oqmd-form-enthalpy.csv\"\n",
    "cfg.EVAL.max_epoch = 20\n",
    "cfg.EVAL.snapshot_inverval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39ec1a10-db40-4eee-a12a-c313a39cecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Eval dataset: oqmd-form-enthalpy.csv\n",
      "NUM TRAIN:230959, NUM VALID:12831, NUM_TEST:12832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 21385/21386 [00:03<00:00, 5413.26it/s]\n",
      "100%|█████████▉| 21385/21386 [00:04<00:00, 5106.01it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 5226.21it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 5121.93it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 5092.06it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 4953.76it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 4840.42it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 4751.04it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 4478.69it/s]\n",
      "100%|█████████▉| 21384/21385 [00:04<00:00, 4289.40it/s]\n",
      "100%|█████████▉| 21384/21385 [00:05<00:00, 4230.19it/s]\n",
      "100%|█████████▉| 21384/21385 [00:05<00:00, 4074.80it/s]\n"
     ]
    }
   ],
   "source": [
    "_train_loader, _valid_loader, _test_loader = EvalLoader()\n",
    "load_pth = os.path.join(cfg.CHECKPOINT_DIR, \"pretrain_0307_3600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dab788e-0b1d-426e-b65c-f5e8deccdbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Start linear evaluation (weights:finetune, target property:formation_energy_per_atom)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isota/workspace/conda_envs/gfinfomax/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([255, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (255) must match the size of tensor b (256) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cfg\u001b[38;5;241m.\u001b[39mWEIGHTS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator(_train_loader, _valid_loader, _test_loader, load_pth)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/isota/unifine/pretrain_cl/evaluate.py:86\u001b[0m, in \u001b[0;36mEvaluator.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 86\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m/workspace/isota/unifine/pretrain_cl/evaluate.py:119\u001b[0m, in \u001b[0;36mEvaluator.eval_model\u001b[0;34m(self, loader, split)\u001b[0m\n\u001b[1;32m    117\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[1;32m    118\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(batch)\n\u001b[0;32m--> 119\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    121\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/workspace/conda_envs/gfinfomax/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/conda_envs/gfinfomax/lib/python3.9/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/conda_envs/gfinfomax/lib/python3.9/site-packages/torch/nn/functional.py:3291\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3289\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3291\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/workspace/conda_envs/gfinfomax/lib/python3.9/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (255) must match the size of tensor b (256) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "cfg.WEIGHTS = \"finetune\"\n",
    "evaluator = Evaluator(_train_loader, _valid_loader, _test_loader, load_pth)\n",
    "evaluator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dadcd9-d7c1-446c-a49f-2883f5e6ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.WEIGHTS = \"freeze\"\n",
    "evaluator = Evaluator(_train_loader, _valid_loader, _test_loader, load_pth)\n",
    "evaluator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822d9c2-70c3-4c3b-b526-1de256598bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.WEIGHTS = \"rand_init\"\n",
    "evaluator = Evaluator(_train_loader, _valid_loader, _test_loader, load_pth)\n",
    "evaluator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72877273-6af4-4ad7-a7fb-9d0a53236287",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(_train_loader))\n",
    "data = data.to(cfg.DEVICE)\n",
    "out = evaluator.decoder(data)\n",
    "print(out.shape)\n",
    "print(data.y.shape)\n",
    "print(data)\n",
    "# batch is missing, last time same issue, check spread graph\n",
    "\n",
    "from torch_geometric.nn import global_add_pool\n",
    "a = global_add_pool(data.node_features_s, data.batch)\n",
    "print(a.shape)\n",
    "data.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db28cf3-8243-4a87-acd6-05ed2ba7eb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfinfomax",
   "language": "python",
   "name": "gfinfomax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
